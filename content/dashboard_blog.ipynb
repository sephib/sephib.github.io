{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Pipeline Monitoring Dashboard\n",
    "\n",
    "These days any project that is deployed should incorporate the principles of CI/CD (highly recommended [great talk from Eric Ma](https://www.youtube.com/watch?v=Dx2vG6qmtPs&t=232s) July 2020 - describes the issue in the realm of _Data Science_).  \n",
    "After setting up our [dagster pipeline](https://dev.to/sephib/implementing-a-graph-network-pipeline-with-dagster-3i3a) we needed to implement some sort monitoring ed\n",
    "solution to review the outcome of our workflow. Working in a small DS team we needed to push forward and couldn't wait for the _heavy guns_ of the enterprise IT to take over. So until we have there support here is a simple dashboard that we put together to monitor our `Assets`.\n",
    "\n",
    "In this blog post we aim to describe how we created a functional dashboard based on python widgets.  \n",
    "We will describe the origin of our data, followed by the our solution using python's Panel library.  \n",
    "\n",
    "* NEED TO INSERT IMAGE OF THE OUTCOME\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dagster Assets   \n",
    "\n",
    "We are not going to dive into [Dagster](https://docs.dagster.io/) (see our previous [blog post on our data pipeline](https://dev.to/sephib/implementing-a-graph-network-pipeline-with-dagster-3i3a)), but the TLDR  is that Dagster is an orchestration framework for building modern data applications and workflows. The framework has integrated logging and the ability to [produce persistent assets](https://docs.dagster.io/overview/asset-materializations#materializing-an-asset) that are stored in a database (in our case postgresql) for future references.   \n",
    "For our project we are interested in monitoring the number of nodes and edges that we generate in our data pipline workflow. During our _pipeline run_ we log (or in the Dagster's jargon Materialize - see [AssetMaterialization in the documnetation](https://docs.dagster.io/examples/materializations#main)) various stats on the datasets that we manipulate. We would like to view the changes of these stats over time in order to verify the health of our system/pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panel widgets  \n",
    "\n",
    "These days the python ecosystem is very rich and vibrant with various visualization libraries that are constatnly beeing developed. Two of the libraries that we reviewed were [streamlit](https://www.streamlit.io/) and [Panel](https://panel.holoviz.org/). We decided on going with Panel which seamed to suite our needs (mainly due to the structure and maintanance approach).  \n",
    "Inspired by a talk given by  [Lina Weichbrodt in the MLOps meetup](https://www.youtube.com/watch?v=Un30yb1WlpU&feature=youtu.be)  we wanted to view the percent change of our metrics over time.   \n",
    "\n",
    "Panel is capable of displaying and integrating many python widgets from various packages. We are going to work with hvplot which is best suited to our needs, due to it's richnes and integration with Pandas.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting our data    \n",
    "In this section we are describing how we extracted the data from Dagster Asset database. If this is not relevant for, you may want to jump to the sample data section.  \n",
    "In order to get the Asset data we needed to dig into the `event_log` table which logs all the events that are generated when running a Dagster pipeline. The code in the [linked repo] extracts the data into a Pandas Dataframe, based on the defined `Asset Keys` that are defined in the `Materialization` process.    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData, select\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "engine = create_engine('postgersql://database_user:user_password@server:port/database_name')\n",
    "conn = engine.connect()\n",
    "meta = MetaData()\n",
    "meta.reflect(engine)\n",
    "t_event_logs = meta.tables['event_logs']  # table which dagster saves all the events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to get all asset_keys in database\n",
    "def get_all_asset_keys(table, filter_asset_keys:str=''):\n",
    "    _sd = select([table.c.asset_key]).distinct(table.c.asset_key)\n",
    "    return [asset_key[0] for asset_key in conn.execute(_sd) if asset_key[0] and filter_asset_keys in asset_key[0]]\n",
    "\n",
    "\n",
    "def get_asset_keys_values(result_list)->dict:\n",
    "    assets={}\n",
    "    for asset_key, res in result_list:\n",
    "        time_stamp = datetime.fromtimestamp(json.loads(res)['timestamp']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "        assets[time_stamp] = {}\n",
    "        assets[time_stamp]['asset_key'] = asset_key\n",
    "        for key_message, value_message in [m.split('=') for m in json.load(res)['message'].split('\\n') if '=' in m]:\n",
    "            if key_message.strip() == 'event_specific_data':\n",
    "                for _event in json.loads(value_message).values():\n",
    "                    if isinstance(_event, list):\n",
    "                        for asset_list in _event[2]:\n",
    "                            assets[time_stamp][asset_list[0]]=asset_list[-1][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = get_all_asset_keys(t_event_logs,'')\n",
    "\n",
    "_s = select([t_event_logs.c.asset_key, t_event_logs.c.event]).where(t_event_logs.c.asset_key.in_(assets))\n",
    "result = conn.execute(_s)\n",
    "result_list = result.fetchall()  # or fetchmany(n)\n",
    "assets = get_asset_keys_values(result_list)\n",
    "\n",
    "df_assets = pd.DataFrame.from_dict(assets, orient='index')\n",
    "df_assets.index = pd.to_datetime(df_assets.index)\n",
    "df_assets_pivot = pd.pivot(df_assets, columns='asset_key')\n",
    "df_assets_pct_change = df_assets_pivot.pct_change()\n",
    "df_assets_pct_change\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Data \n",
    "\n",
    "For the dashboard in this post, we are going to use the sample us_crime data from the `hvplot.sample_data` set.   \n",
    "\n",
    "Since we are simulating our datapipline outcomes we are going to use a sample of the columns:  \n",
    "* Year - as our X / time axis\n",
    "* Violent crime total \t\n",
    "* Murder and nonnegligent Manslaughter\n",
    "* Robbery  \n",
    "\n",
    "Lets view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Robbery</th>\n",
       "      <th>Violent crime total</th>\n",
       "      <th>Murder and nonnegligent Manslaughter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1978</td>\n",
       "      <td>426930</td>\n",
       "      <td>1085550</td>\n",
       "      <td>19560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1968</td>\n",
       "      <td>262840</td>\n",
       "      <td>595010</td>\n",
       "      <td>13800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2013</td>\n",
       "      <td>345095</td>\n",
       "      <td>1199684</td>\n",
       "      <td>14319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Robbery  Violent crime total  Murder and nonnegligent Manslaughter\n",
       "18  1978   426930              1085550                                 19560\n",
       "8   1968   262840               595010                                 13800\n",
       "53  2013   345095              1199684                                 14319"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hvplot.sample_data import us_crime\n",
    "data = us_crime.read()\n",
    "sample_cols = ['Year', 'Robbery', 'Violent crime total', 'Murder and nonnegligent Manslaughter']\n",
    "crim_data = data[sample_cols].copy()\n",
    "crim_data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are interested in the change of volume of the data along the time we can use Panda's [pct_change](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.pct_change.html) method to generate the values that we need.  This also allows to display all the dataset in the same graph since the nominal values of the different datasets are in different order of magnitude.  \n",
    "\n",
    "```\n",
    "cols = [col for col in crim_data.columns if col != 'Year']\n",
    "for c in cols:\n",
    "    crim_data[f'{c}_pct'] = crim_data[c].pct_change()\n",
    "col_pct = [col for col in data.columns if col.endswith('pct')]\n",
    "crime_data = crime_data[['Year'] + col_pct]\n",
    "crime_data.sample(3)\n",
    "```\n",
    "\n",
    "\n",
    "Now that we have the data we can build our dashboard\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard  \n",
    "\n",
    "We have 3 widgets that we want to use in our dashboard:  \n",
    "1. A line plot -  displaying the datasets  \n",
    "2. A CheckBoxGroup widget - allowing to control which dataset will be visible  \n",
    "3. A date_range_slider widget - displaying the date range that we want to display  \n",
    "\n",
    "\n",
    "Our dashboard will display each data series along the X time axis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DateRangeSlider\n",
    "\n",
    "Panel's [DateRangeSlider](https://panel.holoviz.org/reference/widgets/DateRangeSlider.html) widget \"allows selecting a date range using a slider with two handles\".  \n",
    "\n",
    "The parametrs of the widget are self explanitory  \n",
    "\n",
    "```\n",
    "date_range_slider = pn.widgets.DateRangeSlider(\n",
    "        name='Date Range Slider',\n",
    "        start=data[date_col].min(), \n",
    "        end=data[date_col].max(),\n",
    "        value=(data[date_col].max() - timedelta(days=1), data[date_col].max(),)   # defualt value for slider\n",
    ")\n",
    "```  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CheckBoxGroup  \n",
    "\n",
    "Panel's [CheckBoxGroup](https://panel.holoviz.org/reference/widgets/CheckBoxGroup.html) widget \"allows selecting between a list of options by ticking the corresponding checkboxes\".  \n",
    "  \n",
    "The parametrs of the widget are self explanitory \n",
    "\n",
    "```\n",
    " checkbox_widget = pn.widgets.CheckBoxGroup(name='Data sources'\n",
    "                                               , value= cols\n",
    "                                               , options=cols\n",
    "    )\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Line Plot & Panel's Glue  \n",
    "\n",
    "Now lets look at the Line plot code:  \n",
    "\n",
    ">import holoviews.plotting.bokeh  \n",
    ">import hvplot.pandas  \n",
    "\n",
    "These define that [bokeh](https://bokeh.org/) will be the visualization engine for hvplot, in addition to allow for hvplot to directly use Panda's dataframes as the datasources for the plots.  \n",
    "\n",
    "> @pn.depends(date_range_slider.param.value)  \n",
    "\n",
    "The Panel decorator causes the _line plot_ to change based on the value that is changed form the `date_range_slider` widget.   \n",
    "\n",
    "> start_date = date_range\\[0\\], end_date = date_range\\[1\\]  \n",
    "> mask = (crime_data\\[date_col\\] > start_date) & (crime_data\\[date_col\\] <= end_date)   \n",
    "> data = crime_data.loc\\[mask\\]   \n",
    "\n",
    "In order to filter the dataframe we are masking the data based to the current values from the `date_range_slider` widget.  \n",
    "\n",
    "> crime_data.hvplot.line  \n",
    "\n",
    "This is the basic call for a  [line plot] to be rendered from the Panda's dataframe.  \n",
    "```\n",
    " checkbox_widget.jscallback(args={'plot': lines[key]},  \n",
    "                                  value=  \n",
    "                                   \"\"\"  \n",
    "                                   for (var i = 0; i<plot.renderers.length; i++) {  \n",
    "                                         plot.renderers[i].visible = cb_obj.active.indexOf(i) >= 0  \n",
    "                                        }  \n",
    "                                   \"\"\"  \n",
    "```\n",
    "  \n",
    "Here is some JavaScript glue to connect the `hvplot.line` and the `checkbox_widget`(Thx to [Philipp Rudiger](https://discourse.holoviz.org/u/philippjfr/summary) for the reference). We are iterating through the various lines and setting their visibility based on the checkbox_widget values.   \n",
    "\n",
    "Here is the full function:  \n",
    "```\n",
    "@pn.depends(date_range_slider.param.value)\n",
    "def get_plot(date_range):\n",
    "    data = dft\n",
    "    start_date = date_range[0], end_date = date_range[1]\n",
    "    mask = (crime_data[date_col] > start_date) & (crime_data[date_col] <= end_date)\n",
    "    data = crime_data.loc[mask]\n",
    "\n",
    "    lines = data[cols + [date_col]].hvplot.line(\n",
    "          x=date_col\n",
    "        , y=col_pct[1:]\n",
    "        , value_label= 'value'  \n",
    "        , legend='right'\n",
    "        , height=400\n",
    "        , width=800\n",
    "        , muted_alpha=0\n",
    "        , ylim=(-1, 1)\n",
    "        , xlabel='time'\n",
    "        , ylabel='pct'\n",
    "    )\n",
    "    for key in list(dict(lines).keys()):\n",
    "        checkbox_widget.jscallback(args={'plot': lines[key]}\n",
    "                                    ,  value=\n",
    "                                    \"\"\"\n",
    "                                    for (var i = 0; i<plot.renderers.length; i++) {\n",
    "                                      plot.renderers[i].visible = cb_obj.active.indexOf(i) >= 0\n",
    "                                    }\n",
    "                                    \"\"\"\n",
    "        )\n",
    "return lines.opts(axiswise=True)\n",
    "```\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final function\n",
    "\n",
    "Now we can create a functions that connects the different widgets\n",
    "\n",
    "```\n",
    "def get_dashboard(dft, cols, date_col):\n",
    "    date_range_slider = pn.widgets.DateRangeSlider(\n",
    "        name='Date Range Slider',\n",
    "        start=data[date_col].min(), end=data[date_col].max(),\n",
    "        value=(data[date_col].max() - timedelta(days=1), data[date_col].max(),)\n",
    "    )\n",
    "    checkbox_widget = pn.widgets.CheckBoxGroup(name='Data sources'\n",
    "                                               , value= cols\n",
    "                                               , options=cols\n",
    "    )\n",
    "    @pn.depends(date_range_slider.param.value)\n",
    "    def get_plot(date_range):\n",
    "        data = dft\n",
    "        start_date = date_range[0]\n",
    "        end_date = date_range[1]\n",
    "        mask = (data[date_col] > start_date) & (data[date_col] <= end_date)\n",
    "        data = data.loc[mask]\n",
    "\n",
    "        lines = data[cols + [date_col]].hvplot.line(\n",
    "              x=date_col\n",
    "            , y=col_pct[1:]\n",
    "            , value_label= 'value'  \n",
    "            , legend='right'\n",
    "            , height=400\n",
    "            , width=800\n",
    "            , muted_alpha=0\n",
    "            , ylim=(-1, 1)\n",
    "            , xlabel='time'\n",
    "            , ylabel='pct'\n",
    "        )\n",
    "        for key in list(dict(lines).keys()):\n",
    "            checkbox_widget.jscallback(args={'plot': lines[key]}\n",
    "                                       ,  value=\n",
    "                                       \"\"\"\n",
    "                                        for (var i = 0; i<plot.renderers.length; i++) {\n",
    "                                          plot.renderers[i].visible = cb_obj.active.indexOf(i) >= 0\n",
    "                                        }\n",
    "                                       \"\"\"\n",
    "            )\n",
    "        return lines.opts(axiswise=True)\n",
    "    return get_plot, date_range_slider, checkbox_widget\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desgin the Dashboard  \n",
    "\n",
    "Panel has a simple method to aggregate all the widgets together using rows and columns (like a simple HTML table).   \n",
    "\n",
    "<img src=\"../docs/images/panel_layout.png\" alt=\"panel layout\" width=\"450\">  \n",
    "     \n",
    "Below is the code to design the layout  \n",
    "\n",
    "```\n",
    "plot, date_range_slider, checkbox_widget = get_dashboard(data, col_pct, 'Year')\n",
    "dashboard=pn.Row(\n",
    "    pn.Column(\n",
    "        \"Plot\",\n",
    "        date_range_slider, checkbox_widget\n",
    "    )\n",
    "    , plot\n",
    ")\n",
    "dashboard\n",
    "\n",
    "```  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion  \n",
    "In this blog post we outlined our solution for monitoring our Dagster's Assets that we log during our data pipeline workflow.   \n",
    "Using the Panel / hvplot libraries was quite straightforward. The documentation and reference gallaries were very usefull, although getting the linkage between the plot and the checkbox is not optimal since the current solution does not rerender the plot, so it's usefull if the datasets are in the same order of magnitude. However if they were not, this solution should be upgraded to be rerendered as the example in the last section in th [getting started documentation](https://panel.holoviz.org/getting_started/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}